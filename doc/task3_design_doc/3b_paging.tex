
\section{Paging To and From Disk}

\subsection{Data Structures}

% Copy here the declaration of each new or changed `struct' or
% `struct' member, global or static variable, `typedef', or
% enumeration.  Identify the purpose of each in 25 words or less.

\subsection{Frame Eviction}

% When a frame is required but none is free, some frame must be
% evicted.  Describe your code for choosing a frame to evict.
Our code implements the second chance page eviction algorithm.
When no free pages are available, we retrieve a list of all frames and look at the head of that list.
If the access bit of the page in the head frame is set or the frame is pinned, we reset the access bit and reinsert that page into the back of the list.
We continue cycling through the list until we find a frame that is not pinned and whose page's access bit is not set and we evict this page.

Note that if every frame in the list is pinned, instead of iterating endlessly through it, we wait until a frame is either freed or unpinned.
In order to make this algorithm more efficient, we maintain a list of all used frames alongside the hash table.

\subsection{Algorithms - What happens to Q when P evicts Q's frame}

% When a process P obtains a frame that was previously used by a
% process Q, how do you adjust the page table (and any other data
% structures) to reflect the frame Q no longer has?
When P selects Q's page for eviction, it first acquires a lock over that page's supplementary page table entry.
It then disables interrupts while it clears that page from Q's page table (which maps its user virtual address).
The evicted page is either written to swap or, if it represents a memory mapped file, back to disk.
In the first case, we also add the number of the swap slot to the supplementary page entry.
Finally, P releases the lock over the page's supplementary table entry.

% TODO: Somebody needs to talk about the supplementary page table somewhere.

\subsection{Algorithms - Stack Growth Heuristic}

% Explain your heuristic for deciding whether a page fault for an
% invalid virtual address should cause the stack to be extended into
% the page that faulted.

We calculate the difference between the stack pointer and the invalid virtual
address, and see if it is larger than some limit. If it exceeds this limit, then
the user program is deemed to be buggy, and we terminate the thread.

This limit is defined to be 64 bytes, which is two word sizes, and is probably
sufficient as a limit.  Since we do not know every 80x86 assembly instruction,
we simply set the limit to be a large number within reason, instead of spending
a lot of time trying to find the smallest number that would work for the entire
instruction set. We did not want to make the number too large, or risk allowing
buggy user programs.

\subsection{Synchronization - Design}

% Explain the basics of your VM synchronization design.  In
% particular, explain how it prevents deadlock.  (Refer to the
% textbook for an explanation of the necessary conditions for
% deadlock.)

\subsection{Synchronization - Concurrent Accesses during page eviction}

% A page fault in process P can cause another process Q's frame
% to be evicted.  How do you ensure that Q cannot access or modify
% the page during the eviction process?  How do you avoid a race
% between P evicting Q's frame and Q faulting the page back in?
As there is no way of to regulate process Q's access to its own page, we disable interrupts while the page is removed from process Q's frame table.
While the page is being evicted, we use a lock to prevent process Q from attempting to fault its page back in before process P finishes writing the page (either to swap or back to the file it was memory mapped from).

Race conditions related to the frame table itself are avoided with the use of the frame table lock (table_lock inside the frame_table structure).
Any external function that allows a process to modify or access the frame table implicitly acquires this lock before manipulating the frame table.
Hence, in our case, process Q will be blocked until process P finishes evicting the page.

\subsection{Synchronization - Concurrent eviction when reading in page}

% Suppose a page fault in process P causes a page to be read from
% the file system or swap.  How do you ensure that a second process Q
% cannot interfere by e.g. attempting to evict the frame while it is
% still being read in?
A page returned by the request_frame function (the only way to acquire a page) is pinned by default.
In our current implementation, the eviction algorithm cannot evict pinned pages, which allows the caller to finish its operations on its newly acquired page before unpinning it and thus making it possible to evict it.

\subsection{Synchronization - Handling accesses to paged-out pages in syscalls}

% Explain how you handle access to paged-out pages that occur
% during system calls.  Do you use page faults to bring in pages (as
% in user programs), or do you have a mechanism for "locking" frames
% into physical memory, or do you use some other design?  How do you
% gracefully handle attempted accesses to invalid virtual addresses?

We simply use page faults to bring in pages, doing a few sanity checks on each
pointer first before we derefence the pointers and page fault.

We check for threads which attempt to access invalid virtual addresses, which
will be apparent if we cannot find data about a segment that contains the
virtual address.

\subsection{Rationale - Synchronization decisions}

% A single lock for the whole VM system would make
% synchronization easy, but limit parallelism.  On the other hand,
% using many locks complicates synchronization and raises the
% possibility for deadlock but allows for high parallelism.  Explain
% where your design falls along this continuum and why you chose to
% design it this way.
Our design is synchronised via multiple locks, in an attempt to allow as much parallelism as possible.
In order to make synchronisation simpler, we attempted to use implicit synchronisation as far as possible; \textit{e.g.} many external functions (particularly in frame.c) acquire resources on their own instead of relying on the caller to acquire them.
We also tried to avoid excessive synchronisation, that is, synchronising processes that do not require synchronisation. For instance, it is possible to read concurrently from the swap table.
