
\section{Paging To and From Disk}

\subsection{Data Structures}

% Copy here the declaration of each new or changed `struct' or
% `struct' member, global or static variable, `typedef', or
% enumeration.  Identify the purpose of each in 25 words or less.

\subsection{Frame Eviction}

% When a frame is required but none is free, some frame must be
% evicted.  Describe your code for choosing a frame to evict.

\subsection{Algorithms - What happens to Q when P evicts Q's frame}

% When a process P obtains a frame that was previously used by a
% process Q, how do you adjust the page table (and any other data
% structures) to reflect the frame Q no longer has?

We simply clear the page table's mapping of process Q's user virtual address.
% TODO: Add a note here explaining how the supplementary page table is told
% if a page is in swap.

\subsection{Algorithms - Stack Growth Heuristic}

% Explain your heuristic for deciding whether a page fault for an
% invalid virtual address should cause the stack to be extended into
% the page that faulted.

We calculate the difference between the stack pointer and the invalid virtual
address, and see if it is larger than some limit. If it exceeds this limit, then
the user program is deemed to be buggy, and we terminate the thread.

\subsection{Synchronization - Design}

% Explain the basics of your VM synchronization design.  In
% sectioicular, explain how it prevents deadlock.  (Refer to the
% textbook for an explanation of the necessary conditions for
% deadlock.)

\subsection{Synchronization - Concurrent Accesses during page eviction}

% A page fault in process P can cause another process Q's frame
% to be evicted.  How do you ensure that Q cannot access or modify
% the page during the eviction process?  How do you avoid a race
% between P evicting Q's frame and Q faulting the page back in?
As there is no way of to regulate process Q's access to its own page, we disable interrupts while the page is removed from process Q's frame table.
While the page is being evicted, we use a lock to prevent process Q from attempting to fault its page back in before process P finishes writing the page (either to swap or back to the file it was memory mapped from).

Race conditions related to the frame table itself are avoided with the use of the frame table lock (table_lock inside the frame_table structure).
Any external function that allows a process to modify or access the frame table implicitly acquires this lock before manipulating the frame table.
Hence, in our case, process Q will be blocked until process P finishes evicting the page.

\subsection{Synchronization - Concurrent eviction when reading in page}

% Suppose a page fault in process P causes a page to be read from
% the file system or swap.  How do you ensure that a second process Q
% cannot interfere by e.g. attempting to evict the frame while it is
% still being read in?
A page from a request_frame operation is pinned by default.
In our current implementation, the eviction algorithm cannot evict pinned pages, which allows the caller to finish its operations on its newly acquired page before unpinning it and thus making it possible to evict it.

\subsection{Synchronization - Handling accesses to paged-out pages in syscalls}

% Explain how you handle access to paged-out pages that occur
% during system calls.  Do you use page faults to bring in pages (as
% in user programs), or do you have a mechanism for "locking" frames
% into physical memory, or do you use some other design?  How do you
% gracefully handle attempted accesses to invalid virtual addresses?

We simply use page faults to bring in pages, doing a few sanity checks on each
pointer first before we derefence the pointers and page fault.

We check for threads which attempt to access invalid virtual addresses, which
will be apparent if we cannot find data about a segment that contains the
virtual address.

\subsection{Rationale - Synchronization decisions}

% A single lock for the whole VM system would make
% synchronization easy, but limit parallelism.  On the other hand,
% using many locks complicates synchronization and raises the
% possibility for deadlock but allows for high parallelism.  Explain
% where your design falls along this continuum and why you chose to
% design it this way.
